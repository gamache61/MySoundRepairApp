<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sound Breakdown Analyzer</title>
    <link rel="manifest" href="manifest.json">
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f4; }
        #container { max-width: 800px; margin: auto; text-align: center; }
        button { padding: 10px 20px; margin: 10px; font-size: 16px; cursor: pointer; }
        select { padding: 10px; font-size: 16px; }
        #status { font-size: 18px; color: #333; }
        #analysis { margin-top: 20px; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); text-align: left; }
        canvas { display: block; margin: 20px auto; border: 1px solid #ccc; width: 100%; max-width: 600px; height: 200px; }
        #initOverlay { 
            position: fixed; top: 0; left: 0; width: 100%; height: 100%; 
            background: rgba(255,255,255,0.9); display: flex; align-items: center; 
            justify-content: center; z-index: 1000; 
        }
    </style>
</head>
<body>
    <div id="initOverlay">
        <button id="initBtn" style="padding: 20px; font-size: 20px; background: #008000; color: white; border: none; border-radius: 8px;">Enable Microphone & Start App</button>
    </div>

    <div id="container">
        <h1>Sound Breakdown Analyzer</h1>
        <p>This offline web app records sounds from your microphone, analyzes them for potential breakdowns in everyday items, and provides basic diagnostics.</p>
        
        <label for="category">Select Item Category:</label>
        <select id="category">
            <option value="appliance">Appliance (e.g., Washer, Fridge)</option>
            <option value="vehicle">Vehicle (e.g., Car Engine, Brakes)</option>
            <option value="machine">Machine (e.g., Fan, Pump)</option>
            <option value="structure">Structure (e.g., Door Hinge, Pipe)</option>
            <option value="other">Other</option>
        </select>
        <br>
        <button id="startBtn" disabled>Start Recording</button>
        <button id="stopBtn" disabled>Stop Recording</button>
        <button id="analyzeBtn" disabled>Analyze Sound</button>
        
        <div id="status">Please click the green button to start.</div>
        
        <canvas id="waveform" width="600" height="200"></canvas>
        
        <div id="analysis"></div>
    </div>

    <script>
        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let analyzer;
        let scriptProcessor;
        let canvasCtx = document.getElementById('waveform').getContext('2d');
        let audioBlob;

        const initOverlay = document.getElementById('initOverlay');
        const initBtn = document.getElementById('initBtn');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const status = document.getElementById('status');
        const categorySelect = document.getElementById('category');
        const analysisDiv = document.getElementById('analysis');

        initBtn.onclick = () => {
            initAudio();
            initOverlay.style.display = 'none';
        };

        async function initAudio() {
            try {
                // Constraints for better iOS compatibility
                const constraints = { audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Initialize AudioContext (standard + webkit for iOS)
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContextClass();
                
                // Resume context immediately (crucial for iOS)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                // Setup MediaRecorder
                mediaRecorder = new MediaRecorder(stream);
                
                const source = audioContext.createMediaStreamSource(stream);
                analyzer = audioContext.createAnalyser();
                analyzer.fftSize = 2048;
                source.connect(analyzer);
                
                // ScriptProcessor is deprecated but kept for your existing logic; 
                // added connection to output to ensure the clock runs
                scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);
                analyzer.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                scriptProcessor.onaudioprocess = drawWaveform;
                
                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) audioChunks.push(e.data);
                };

                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    analyzeBtn.disabled = false;
                    status.textContent = 'Recording stopped. Ready to analyze.';
                };
                
                startBtn.disabled = false;
                startBtn.onclick = () => {
                    audioChunks = [];
                    mediaRecorder.start();
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    analyzeBtn.disabled = true;
                    status.textContent = 'Recording...';
                };
                
                stopBtn.onclick = () => {
                    mediaRecorder.stop();
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    status.textContent = 'Processing...';
                };
                
                analyzeBtn.onclick = analyzeSound;
                status.textContent = 'Ready to record.';

            } catch (err) {
                status.textContent = 'Error: ' + err.message;
                console.error(err);
            }
        }

        function drawWaveform() {
            if (!analyzer) return;
            const bufferLength = analyzer.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyzer.getByteTimeDomainData(dataArray);
            
            canvasCtx.clearRect(0, 0, 600, 200);
            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = 'rgb(0, 128, 0)';
            canvasCtx.beginPath();
            
            const sliceWidth = 600 / bufferLength;
            let x = 0;
            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * 100;
                if (i === 0) canvasCtx.moveTo(x, y);
                else canvasCtx.lineTo(x, y);
                x += sliceWidth;
            }
            canvasCtx.lineTo(600, 100);
            canvasCtx.stroke();
        }

        function analyzeSound() {
            if (!analyzer) return;
            status.textContent = 'Analyzing...';
            analysisDiv.innerHTML = '';
            
            const bufferLength = analyzer.frequencyBinCount;
            const freqData = new Uint8Array(bufferLength);
            analyzer.getByteFrequencyData(freqData);
            
            let low = 0, mid = 0, high = 0;
            const third = Math.floor(bufferLength / 3);
            for (let i = 0; i < third; i++) low += freqData[i];
            for (let i = third; i < 2 * third; i++) mid += freqData[i];
            for (let i = 2 * third; i < bufferLength; i++) high += freqData[i];
            
            low /= third;
            mid /= third;
            high /= (bufferLength - 2 * third);
            
            const category = categorySelect.value;
            let diagnosis = '';
            let advice = '';
            
            if (high > 80) { // Slightly lowered threshold for mobile mics
                diagnosis = 'High-frequency noise detected – possible grinding, squeaking, or loose parts.';
                if (category === 'appliance') advice = 'Check for unbalanced loads or worn bearings.';
                else if (category === 'vehicle') advice = 'Could be brake pads or belt issues.';
                else advice = 'Look for friction points. Lubricate if possible.';
            } else if (low > 80) {
                diagnosis = 'Low rumble or humming – might indicate imbalance or motor strain.';
                if (category === 'appliance') advice = 'Level the appliance or check for blockages.';
                else if (category === 'vehicle') advice = 'Possible engine or exhaust problem.';
                else advice = 'Ensure stable mounting.';
            } else {
                diagnosis = 'Sound appears normal.';
                advice = 'Continue monitoring regularly.';
            }
            
            analysisDiv.innerHTML = `
                <h2>Analysis Results</h2>
                <p><strong>Category:</strong> ${category.charAt(0).toUpperCase() + category.slice(1)}</p>
                <p><strong>Diagnosis:</strong> ${diagnosis}</p>
                <p><strong>Advice:</strong> ${advice}</p>
                <p><strong>Frequency Breakdown:</strong> Low: ${low.toFixed(2)}, Mid: ${mid.toFixed(2)}, High: ${high.toFixed(2)}</p>
            `;
            status.textContent = 'Analysis complete.';
        }

        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('sw.js').catch(err => console.error(err));
            });
        }
    </script>
</body>
</html>